{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c419c8a2-b5a9-4e13-aaa7-88a00baba9b2",
   "metadata": {},
   "source": [
    "## USGS and EMIT Data Matchup\n",
    "In this notebook we will search the USGS database for a specific state code and paramater code/s to retrieve a list of sites. We will then use the site coordinates to find matching EMIT granules and gather data around the EMIT granules time stamp. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41880e8d-fd8d-481b-920d-b82e128e21a9",
   "metadata": {},
   "source": [
    "### 1. Retrieving site codes\n",
    "First import package and utils file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c2238e-8c67-4494-b271-0f1c37c997c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataretrieval.nwis as nwis\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, box, Polygon, MultiPolygon\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import earthaccess\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('modules/')\n",
    "from retrieval_utils import get_param_sites, get_all_site_granules, match_granules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44a4fe3-664c-4113-b3f4-bc1b76688093",
   "metadata": {},
   "source": [
    "Next we can find active parameters using the USGS website, for a separate guide on this there is a PDF called \"Get param codes\" in the Github. \n",
    "\n",
    "Then we can define the time-frame, state code and paramater codes and call the function. Note: all three are required for the function to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4374ff-c5bc-4c75-aa8b-24bd2e4155c1",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparam_codes = [\\'32316\\'] # chla fluorescence\\nparam_codes_str = \\',\\'.join(param_codes) \\n# state_code = \\'06\\' # california\\nstate_codes = [f\"{i:02d}\" for i in range(1, 57)]\\nsite_types = [\\'LK\\', \\'ES\\'] # lakes, estruaries\\nsite_list = get_param_sites(param_codes_str, state_codes, site_types)\\n\\nprint(site_list.head())\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "param_codes = ['32316'] # chla fluorescence\n",
    "param_codes_str = ','.join(param_codes) \n",
    "# state_code = '06' # california\n",
    "state_codes = [f\"{i:02d}\" for i in range(1, 57)]\n",
    "site_types = ['LK', 'ES'] # lakes, estruaries\n",
    "site_list = get_param_sites(param_codes_str, state_codes, site_types)\n",
    "\n",
    "print(site_list.head())\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e98d5194-a9c7-415b-af8d-83d360550cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6b8dfb-e27c-4756-8a8b-fe3a86fa55f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Category               ID   Latitude   Longitude  \\\n",
      "0  BLUE RIVER LAKE NEAR BLUE RIVER  441022000000000  44.173194 -122.324222   \n",
      "1  BLUE RIVER LAKE NEAR BLUE RIVER  441022000000000  44.173194 -122.324222   \n",
      "2  BLUE RIVER LAKE NEAR BLUE RIVER  441022000000000  44.173194 -122.324222   \n",
      "3  BLUE RIVER LAKE NEAR BLUE RIVER  441022000000000  44.173194 -122.324222   \n",
      "4  BLUE RIVER LAKE NEAR BLUE RIVER  441022000000000  44.173194 -122.324222   \n",
      "\n",
      "                      Date  Band  wavelength   fwhm  reflectance  \\\n",
      "0  2023-08-12 22:32:34 UTC  B001     381.006  8.415     0.020886   \n",
      "1  2023-08-12 22:32:34 UTC  B002     388.409  8.415     0.021061   \n",
      "2  2023-08-12 22:32:34 UTC  B003     395.816  8.415     0.022508   \n",
      "3  2023-08-12 22:32:34 UTC  B004     403.225  8.415     0.025560   \n",
      "4  2023-08-12 22:32:34 UTC  B005     410.638  8.417     0.027297   \n",
      "\n",
      "   good_wavelengths        elev  \n",
      "0               1.0  369.370332  \n",
      "1               1.0  369.370332  \n",
      "2               1.0  369.370332  \n",
      "3               1.0  369.370332  \n",
      "4               1.0  369.370332  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "spec_df = pd.read_csv('data/sites_spectra_app2.csv', dtype={'ID': str})\n",
    "\n",
    "def fix_id(id_value):\n",
    "    try:\n",
    "        # Check if the ID contains 'E' or 'e' indicating scientific notation\n",
    "        if 'E' in id_value.upper():\n",
    "            # Convert the scientific notation string to a float, then to an integer, then back to a string\n",
    "            id_fixed = str(int(float(id_value)))\n",
    "            return id_fixed\n",
    "        else:\n",
    "            return id_value  # Return the ID as is if it's not in scientific notation\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting ID {id_value}: {e}\")\n",
    "        return id_value  # Return the original value if conversion fails\n",
    "\n",
    "# Apply the function to the 'ID' column\n",
    "spec_df['ID'] = spec_df['ID'].apply(fix_id)\n",
    "\n",
    "# Verify the IDs after conversion\n",
    "print(spec_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d0e82d-fe14-4fcd-a8f8-08ee848fc670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a188e-413c-45a9-ada4-536bed5c7bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d773be50-347f-40b1-aa5a-6f44ae249ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "spec_df = pd.read_csv('data/site_spectra_app2.csv', dtype={'ID': str})\n",
    "\n",
    "grouped = spec_df.groupby(['ID', 'Date'])\n",
    "\n",
    "scenes = []\n",
    "\n",
    "for (site_id, date), group in grouped:\n",
    "    # Collect spectral data into a list of dictionaries\n",
    "    spectral_data = group[['Band', 'wavelength', 'reflectance']].to_dict('records')\n",
    "    \n",
    "    # Create a dictionary for the scene\n",
    "    scene = {\n",
    "        'site_no': site_id,\n",
    "        'datetime': date,\n",
    "        'station_nm': group['Category'].iloc[0],\n",
    "        'lat': group['Latitude'].iloc[0],\n",
    "        'lon': group['Longitude'].iloc[0],\n",
    "        'spectra': spectral_data\n",
    "    }\n",
    "    \n",
    "    scenes.append(scene)\n",
    "\n",
    "scenes_df = pd.DataFrame(scenes)\n",
    "\n",
    "scenes_df['datetime'] = pd.to_datetime(scenes_df['datetime'])\n",
    "scenes_df['datetime'] = scenes_df['datetime'].dt.strftime('%Y-%m-%dT%H:%M:%S.000Z')\n",
    "\n",
    "# Display the first few rows\n",
    "print(len(scenes_df['site_no'].unique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c9974-5a14-43c6-af9a-8ec0e73cfe5e",
   "metadata": {},
   "source": [
    "### 2. Retrieving granules based on site locations\n",
    "Now we have the site list we can use coordinates to search for matching granules. \n",
    "\n",
    "Next setup the granule search and call the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b617233-065f-485d-9a31-270b87e82e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sites: 100%|███████████████████████████| 5/5 [00:05<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    site_no                                      station_nm     site_lat  \\\n",
      "0  11455508  SUISUN BAY A VAN SICKLE ISLAND NR PITTSBURG CA  38.04953056   \n",
      "1  11455508  SUISUN BAY A VAN SICKLE ISLAND NR PITTSBURG CA  38.04953056   \n",
      "2  11455508  SUISUN BAY A VAN SICKLE ISLAND NR PITTSBURG CA  38.04953056   \n",
      "3  11455508  SUISUN BAY A VAN SICKLE ISLAND NR PITTSBURG CA  38.04953056   \n",
      "4  11455508  SUISUN BAY A VAN SICKLE ISLAND NR PITTSBURG CA  38.04953056   \n",
      "\n",
      "     site_lon                                       granule_urls  \\\n",
      "0  -121.88755  [https://data.lpdaac.earthdatacloud.nasa.gov/l...   \n",
      "1  -121.88755  [https://data.lpdaac.earthdatacloud.nasa.gov/l...   \n",
      "2  -121.88755  [https://data.lpdaac.earthdatacloud.nasa.gov/l...   \n",
      "3  -121.88755  [https://data.lpdaac.earthdatacloud.nasa.gov/l...   \n",
      "4  -121.88755  [https://data.lpdaac.earthdatacloud.nasa.gov/l...   \n",
      "\n",
      "                   datetime  \n",
      "0  2023-03-27T23:01:16.000Z  \n",
      "1  2023-05-27T22:53:15.000Z  \n",
      "2  2023-08-07T18:27:32.000Z  \n",
      "3  2023-08-14T22:34:53.000Z  \n",
      "4  2023-08-18T21:00:19.000Z  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_date_dt = dt.datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end_date_dt = dt.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "dt_format = '%Y-%m-%dT%H:%M:%SZ'\n",
    "temporal_str = start_date_dt.strftime(dt_format) + ',' + end_date_dt.strftime(dt_format)\n",
    "\n",
    "\n",
    "site_granules = get_all_site_granules(site_list, temporal_str)\n",
    "df_granules = pd.DataFrame(site_granules)\n",
    "print(df_granules.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0db453c-f0ec-49aa-9b56-6c692ac87e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print(len(df_granules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5295e8ec-479e-4f65-b500-0c72edaafd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching IDs: 0 out of 184\n",
      "IDs in scenes_df not found in site_list_clean:\n",
      "0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "1552    False\n",
      "1553    False\n",
      "1554    False\n",
      "1555    False\n",
      "1556    False\n",
      "Name: site_no, Length: 1557, dtype: bool\n",
      "0             72632996\n",
      "1              7362591\n",
      "2             11173200\n",
      "3             11273400\n",
      "4             11312676\n",
      "            ...       \n",
      "191            4084500\n",
      "192            4085059\n",
      "193           40851385\n",
      "194            5545750\n",
      "195    465130091060701\n",
      "Name: site_no, Length: 196, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "site_list = pd.read_csv('data/chla_sites2.csv', dtype={'ID': str})\n",
    "\n",
    "scenes_df['site_no'] = scenes_df['site_no'].astype(str)\n",
    "matching_ids = scenes_df['site_no'].isin(site_list['site_no'])\n",
    "num_matching_ids = matching_ids.sum()\n",
    "total_ids = len(scenes_df['site_no'].unique())\n",
    "\n",
    "print(f\"Number of matching IDs: {num_matching_ids} out of {total_ids}\")\n",
    "\n",
    "# Optionally, list IDs that do not match\n",
    "non_matching_ids = scenes_df.loc[~matching_ids, 'site_no'].unique()\n",
    "print(\"IDs in scenes_df not found in site_list_clean:\")\n",
    "print(matching_ids)\n",
    "print(site_list['site_no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5146bdc-fdb8-4ce3-841a-83abcc2a745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = match_granules(scenes_df, ['32316'])\n",
    "print(len(results))\n",
    "results.to_csv('data/results_chla_app2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
